OUTLIER REMOVE
===

## 1. [Outlier removal](https://adioshun.gitbooks.io/pcl-tutorial/content/part-1/part01-chapter04/)
- 모든 센서는 특성상 측정시 에러가 존재
- Lidar의 경우 탐지 물체가 존재 하지 않아도 먼지나 오류 등으로 인해 point가 생성
- 이렇게 생성된 point들은 Noise또는 Outlier라 하고 제거 하는 작업을 진행
- 이를 Noise filtering또는 Outlier Removal이라고 하며 아래와 같은 방법이 존재
  - Statistical based : 통계적 방법 활용
  - Radius based : 거리 정보 활용

### 1-1. StatisticalOutlierRemoval filter

![image](https://user-images.githubusercontent.com/108650199/199907029-f9eced30-42a5-4b5b-aa33-db10f1a6d2af.png)

- 통계학적 정보를 이용하여 Noise를 탐지 하는 방법 
#### - 방법
- 1) 이웃 근접 point 들과의 평균 거리 정보를 계산
- 2) 이 분포가 Gaussian distribution따른다는 가정하에 나머지는 잡음으로 간주 제거
#### - [KNN algorithm](https://bkshin.tistory.com/entry/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-6-K-%EC%B5%9C%EA%B7%BC%EC%A0%91%EC%9D%B4%EC%9B%83KNN)

![image](https://user-images.githubusercontent.com/108650199/199907462-78f3f979-83d9-4342-bca4-8b8a42c5133a.png)

- K-최근접 이웃(K-Nearest Neighbor, KNN)은 지도 학습 알고리즘 중 하나
- 어떤 데이터가 주어지면 그 주변(이웃)의 데이터를 살펴본 뒤 더 많은 데이터가 포함되어 있는 범주로 분류하는 방식
- 새로운 데이터가 주어졌을 때 (빨간 점) 이를 Class A로 분류할지, Class B로 분류할지 판단하는 문제
##### - example
- k=3일 때, 가장 가까운 주변의 3개 데이터를 본 뒤, 3개의 주변 데이터가 더 많이 포함되어 있는 범주로 분류하겠다는 것
  - 빨간 점 주변에 노란색 점(Class A) 1개와 보라색 점(Class B) 2개가 있음
  - 따라서 k=3 일 때는 해당 데이터가 Class B (보라색 점)으로 분류
- k=6일 때, 원 안에 노란색 점 4개와 보라색 점 2개가 있음
  - 따라서 k=6일 때는 노란색 점으로 분류
- KNN은 K를 어떻게 정하냐에 따라 결과 값이 바뀜
- K가 너무 작아서도 안 되고, 너무 커서도 안됨
- K의 default 값은 5이며, 일반적으로 K는 홀수를 사용

### 1-2. Radius Outlier removal

![image](https://user-images.githubusercontent.com/108650199/199912240-dbf23bfb-372e-427c-a1d5-cecbfc859046.png)

- 거리 정보를 이용한 가장 간단한 Noise를 탐지 하는 방법
#### - 방법
- 1) 탐색 반경 / 최소 포인트 수 정의 
  - 원래의 포인트 클라우드의 각 포인트가 지정된 반경 이웃에 최소한 특정 수의 이웃을 포함한다고 가정
  - 만약 반경이 1에 최소 이웃이 2이면, 반경 넘어가면 지우고, 반경안에 1개면 less니까 지운다는 뜻뜻
- 2) 특정 포인트의 반경내 지정된 포인트 이하인경우 잡음으로 간주 제거
