LIDAR
===

> Reference : https://gaussian37.github.io/autodrive-lidar-intro/
> > https://gaussian37.github.io/autodrive-lidar-lidar_pointcloud_process/
> > 무조건 한 번 더 읽어보기! 정리가 잘되어있음

### 0. LiDAR
#### - 라이다의 감지 방식

- LiDAR(Light Ditection And Ranging)의 약자로 TOF(Time of Flight)를 측정하는 레이저 센서 형태의 원격 감지 방식

  ![image](https://user-images.githubusercontent.com/108650199/186300084-7169ec64-14ef-43a2-9e57-1d3be1d79569.png)  
  
  - TOF : 피사체를 향해 쏜 빛이 object에 맞아 반사되어 되돌아오는 시간을 측정해 거리를 측정하는 방식
    - 빛의 속도는 일정하기 때문에(약 299 792 458 m/s) Lidar는 센서와 물체 사이의 정확한 거리를 실시간으로 제공
    - 공식 (c는 빛의 속도, t는 피사체에서 object까지의 거리)
    - TOF 종류
    - TOF(직접비행시간거리측정) : 라이다가 피사체를 향해 쏜 빛이 오브젝트에 맞아 되돌아오는 시간을 측정해 거리를 측정
    - iTOF(간접비행시간거리측정) : 빛의 연속적인 사인파를 이용하여, 전송된 파형과 반사된 파형 사이의 위상 차이를 통해 비행시간을 측정

    ![image](https://user-images.githubusercontent.com/108650199/186330157-95024d1e-17fa-4aee-a43c-3804dc4df390.png)

  - 좀더 세부적으로 분류를 하면 라이다는 Light Ditection And Ranging라는 이름의 기술로 불리며 ToF와 작동방식과 방정식은 동일
    - but, 라이다는 채널 수 만큼 레이저 펄스를 쪼개어 쏘는데 이 레이저 펄스를 이용하여 센서 주변의 구조를 인식하며, 이후 라이다는 포인트 클라우드를 만들어 3D맵을 만듦
  - LiDAR의 커버 범위는 모델에 따라 수 미터에서 킬로미터
  
#### - 🌟️ esolution 🌟️
- Resolution 
  - 서로 떨어져 있는 두 물체를 서로 구별할 수 있는 능력으로 라이다는 각도 분해능의 성능이 중요
  - 각도 분해능은 먼 거리에서 농구공과 같은 물체를 감지·분류할 수 있는지, 아니면 단지 물체의 존재 여부만 감지할 수 있는지를 결정
    - 이를 통해 백-엔드 프로세싱 없이도 물체들의 특징을 한 장면으로 3D 묘사할 수 있음
    - but, 레이더의 파장은 장거리 갈수록 공간 분해능이 떨어져 물체 인식률이 떨어져 작은 특징을 분석하는데 애를 먹음

    ![image](https://user-images.githubusercontent.com/108650199/186332454-09f8abf9-48d6-4c3e-ae0a-9abafbd9afcd.png)

#### - FOV(Field of View)
- 360° 회전을 하는 기계식 라이다 시스템은 모든 ADAS(Advanced Driver Assistance Systems) 기술 중에서도 가장 넓은 FOV를 가지고 있음
- 라이다는 수직 FOV(고도)에서 레이더보다 뛰어남
- 또한, 라이다는(방위각과 고도 모든) 각도 분해 능에서도 레이더보다 우위에 있으며 이는 물체 분류를 개선하는데 꼭 필요한 핵심 기능

#### - 라이다의 파장 대역 905nm vs 1550nm

![image](https://user-images.githubusercontent.com/108650199/186304511-0309b9ac-04f1-4593-be35-34de594df4e5.png)

- 1. 905nm
  - 장점
    - 양산이 쉬우며, 가격을 낮출 수 있고, 소모 전력이 낮음
    - 물에 의한 흡수력이 1550nm보다 낮아서 공기 중의 수분에 상대적으로 영향을 덜 받음
  - 단점
    - 지구로 투과되는 태양광이 905nm 대역이 더 많으므로 태양광에 의한 노이즈 현상이 더 많을 수 있음
    - 상대적으로 낮은 탐지거리 (최대 200m 범위)
- 2. 1550nm
  - 장점
    - 905nm 보다 시력 손상이 없음 (905nm도 Eye-safety Class 1 이라서 시력 손상이 없지만 비교하자면 1550nm가 더 안전)
    - 상대적으로 높은 탐지거리
    - 상대적으로 적은 태양광 노이즈
  - 단점
    - 높은원가로 인하여 양산이 어렵
    - 물에 의한 흡수력이 905nm보다 높아서 공기 중의 수분에 영향을 더 받음 > but, 출력(세기)를 높여서 문제 해결 중
    -  출력 높임으로 인해서 탐지거리가 길지만 소모 전력이 큼
     
#### - 구동방식에 따른 라이다 센서의 종류

![image](https://user-images.githubusercontent.com/108650199/186347512-59d55c95-88ca-4c82-bc5e-ea0dc9dc069c.png)

- 1. Mechanical Scanning Lidar

![image](https://user-images.githubusercontent.com/108650199/186304815-3baf4b90-a8e5-4e0d-a3a9-370e435bc9ca.png)

  - 모터를 이용하여 물리적으로 센서를 회전시켜 주변을 스캔
    - 장점: 수평 FOV가 넓음(360도)
    - 단점: 크기가 크고, 가격이 비교적 비싸며 내구성이 약함

- 2. Solid State Lidar
  - 고정형 라이다로 회전하는 기계식 장치가 없고, 수평 FOV가 좁으므로 더욱 저렴
  - 차량의 전방과 후방, 측면의 여러 채널들을 이용해 그 데이터들을 융합하면 기계식 라이다에 필적하는 FOV가 만들어짐
  - ex) MEMS Lidar, OPA(Optical Phase Array), Flash Lidar


  - 2-2. MEMS Lidar
  ![image](https://user-images.githubusercontent.com/108650199/186304972-a3f067a8-53a8-479d-9e66-1e663747c00a.png)
    - 전압으로 기울기가 달라지는 작은 미러를 사용함
      - 사실상, 기계식 스캐닝 하드웨어를 전자기계식으로 대체한 것이 MEMS 시스템
    - 여러 가지 차원으로 빛을 이동시키기 위해 복수 미러들을 연속적으로 늘어놓는 구조
      - 장점 : 크기가 작고 가격이 비교적 저렴
      - 단점 : 충격과 진동에 약하며 FOV가 좁음
  - 2-2. OPA, Optical Phase Array

  ![image](https://user-images.githubusercontent.com/108650199/186305273-119ff03e-938b-4904-8586-370209dee084.png)

    - 광학 위상 모듈레이터가 렌즈를 통과하는 빛의 속도를 제어하여 전방으로 나가는 빛의 파면 형상을 제어하고 빔을 여러 방향으로 쏘아 물체를 인식하는 방식 
      - 장점 : 크기가 작고 가격이 비교적 저렴
      - 단점 : FOV가 좁음
  - 2-3. Flash Lidar

  ![image](https://user-images.githubusercontent.com/108650199/186305493-14587921-887e-471d-84ae-d43242a0cc2c.png)

    - 레이저를 전방에 비추고 레이저 가까이 위치한 수신기에서 반사된 산란광을 포착, 단 하나의 이미지로 전체 장면을 포착하는 방식
      - 장점 : 진동에 강하며 이미지 장면 포착 속도가 빠름
      - 단점 : 전체 장면을 비추고 멀리 보는데 높은 레이저 출력이 필요하며, 빛을 반사시키는 물체로 인해 센서데이터를 무용지물로 만들 수 있음

![image](https://user-images.githubusercontent.com/108650199/186336871-8d64b081-d5ee-4f3a-8fd6-24f58c49edae.png)

#### - LiDAR의 프로세서

![image](https://user-images.githubusercontent.com/108650199/186343789-598bbdf7-dcfa-4d29-b652-d136dd899f75.png)

- ① Emitter : 레이저를 송출하는 역할
- ② Scanning System : 송출한 레이저를 주변 환경에 맞게 조사하는 역할
- ③ Receiver : 반사되어 들어오는 빛을 다시 측정하는 역할
- ④ Signal Processing : Emitter ~ Receiver 까지 걸린 시간을 이용하여 각 포인트 마다의 거리를 계산하는 역할
- ⑤ Software : Signal Processing을 통해 얻은 각 Point 정보를 이용하여 주변 물체에 대한 측정 결과를 제공

#### - LiDAR의 기본 원리

![image](https://user-images.githubusercontent.com/108650199/186346670-85e4db35-32fc-46af-8314-c6645c8b6eb9.png)

- ① PC : 프로세싱을 하는 컴퓨터 모듈을 의미
- ② timing module : 라이다 전체 동작의 타이밍을 처리하는 모듈을 의미
  - 위 그림과 같은 Scanning type Lidar는 시간차를 이용하기 때문에 타이밍 처리가 중요
  - timing module은 laser를 쏘우라고 laser에 신호를 보내며 이 때, 시간은 t1
- ③ laser : laser는 이 때, 신호를 받고 laser를 쏘게 되며, 일반적인 laser beam 처럼 계속 쏘는 것은 아니며 일시적으로 Pusle를 쏘게 됨
- ④, ⑤ mirror : mirror를 통하여 원하는 곳으로 laser를 전달
- ⑥ laser pulse : t1시간에 쏜 laser의 pulse가 출력
- ⑦ refelected pulse : laser pulse가 물체를 맞고 반사되어 들어옴
  - 맞고 돌아오는 pulse는 일반적으로 laser pulse 보다 energy가 작음
- ⑧ mirror : 반사되어 돌아온 pulse는 거울에 반사되어 detector로 전달
- ⑨ detector : detector에서는 반사되어 돌아온 pulse를 인식
- ⑩ timing module : 반사되어 돌아온 pulse의 수신 시간을 t2라고 하면 위 그림의 t1,t2 시간 차이를 이용하여 거리를 구할 수 있으며 위 식에서 사용된 C 는 빛의 속도를 의미

![2](https://user-images.githubusercontent.com/108650199/186347183-a2417ff8-021d-4658-b4fb-473715adc5d3.gif)


- 즉, lidar는 laser가 반사되어 돌아오는 것을 통하여 물체의 거리를 측정하는 방식이며 반사되어 돌아오는 시간을 이용하여 물체의 거리 계산
  - 위 그림의 초록색 점이 point cloud라고 하며 lidar를 통해 인식하는 데이터임
  - 마치 카메라를 통해 인식하면 픽셀마다 컬러 값이 존재하게 되는데 이와 대응된다고 볼 수 있음
- 위 그림과 같이 mirror를 회전시켜서 laser를 원하는 영역까지 송신하고 반사되는 위치를 인식하므로 물체의 최근접점을 인식
  - 반사된 거리를 인식하기 때문에 뒤에 가려진 물체는 인식하기 어려움
- lidar 구조 이미지에서 ③ laser (발광부)와 ⑧ detector (수광부)는 한 쌍으로 이루어져 있음
  - 만약 많은 point cloud를 얻기 위하여 여러개의 발광부와 수광부를 사용할 수도 있지만 이런 경우에는 가격이 비싸지게 되므로 거울을 통해 반사하는 형식을 사용


### 1. LiDAR vs Camera vs Radar

- 거리 비교

![image](https://user-images.githubusercontent.com/108650199/186303753-c5633c51-96e2-49b4-ae74-14adf54c750b.png)

- 전체적 비교

![image](https://user-images.githubusercontent.com/108650199/186301657-a2674efc-94bd-4f67-885c-7ad223696376.png)

- 장단점 비교

![image](https://user-images.githubusercontent.com/108650199/186303903-06c670f6-8638-472b-92f9-088f07827209.png)

### 2. 2D vs 3D LiDAR
![image](https://user-images.githubusercontent.com/108650199/186300260-68131108-9f4d-40e9-8d11-e3bac4a64b05.png)

![image](https://user-images.githubusercontent.com/108650199/186311048-fdc0c934-88e0-4fd9-8d86-9ef38bb6ab50.png)

- 1D Lidar
  - 축에 단일 레이저 펄스를 보냄
  - 즉, 단일 점 까지의 거리를 계산 (ex, 디지털 거리재는 자)
    - 용도 : UAV가 지면에서 높이를 감지하거나 모바일 로봇이 앞에서의 벽까지 거리 감지
- 2D Lidar
  - 단일 평면에서 감지하기 위한 하나의 레이저 빔만 포함
    - 즉, 2D LIDAR는 X축과 Y축에서만 객체 데이터를 수집하려고 하기 때문에 광선은 객체의 수평면을 따라서만 발사
  - 이 레이저 센서는 주로 평면도를 만드는데 사용
- 3D Lidar
  - 평면이 아니라 3차원으로 봄
    - 즉, 3D LIDAR는 대상의 수직면을 따라 빔의 초점을 맞춰 X, Y 및 Z축의 3차원 데이터를 캡처
  - 여러 평면에서 동시 측정을 위한 여러 레이저 빔(모델에 따라 16~128)이 포함
  - 포인트 클라우드는 3D 공간의 많은 포인트일 뿐이며 2D 스캔보다 훨씬 풍부한 주변 환경 표현을 제공할 수 있음
  - 쉽게 말하자면 라이다는 빛 즉 레이저를 이용하여 고해상도의 3차원 정보를 제공하는 센서
