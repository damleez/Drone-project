BACKEND
===

## 1. 개요
### 1.1 상태 추정의 확률 해석
- odometry는 순서적인 형태의 짧은 궤적만을 가지지만 우리는 전체 운동 궤적이 오랫동안 최적 상태로 유지되기를 바람
- 따라서, Backend Optimization에서 우리는 장시간(또는 모든 시간) 상태 추정 문제를 고려하고 과거 정보를 사용하여 상태를 업데이트할 뿐 아니라 향후 정보로 업데이트 함
  - 이를 🌟️ Batch Process 🌟️ 라고 함
- 이와는 다르게 현재 상태가 과거 순간 또는 바로 이전 순간에 의해서만 결정되는 경우 🌟️ Incremental 🌟️ 이라고 함

```
Xk=f(Xk-1,uk)+wk
```

- 요런식으로 관측데이터 등을 설정하는데 여기서 우리는 방정식이 잡음의 영향을 받음을 가정
- 다변수 확률 분포를 따르는 확률 분포라고 가정하는데, 즉 상태량과 잡음이 🌟️ 가우시안 분포 🌟️를 따른다고 가정
  - 가우시안 분포를 사용하기 위해 평균 및 공분산 행렬을 지정짐
    - 평균 : 변수의 최적 값의 추정치
    - 공분산 행렬 : uncertainty\
- 그러면 과연 motion data와 관측 data가 있을 때 상태량의 가우스 분포는 어떻게 측정?
  - 시간이 지날수록 위치에 대해 불확실성이 커짐 > 왜냐? 잡음이 점점 쌓이니까
    - 다시말하자면 입력 데이터가 노이즈의 영향을 받을 때, 위치 분산을 더 많이 추정
  - 하지만, 만약 움직일 때 외부 장면을 지속적으로 관찰하고 위치 추정의 불확실성을 줄인다면 점점 더 위치에 대해 확실하게 됨
    - 즉, 가우시안 분포로 가정하여 타원 또는 타원체로 공분산 행렬을 시각적으로 표현 
    - 그렇다면 올바른 관찰을 한다면 원은 특정 크기로 줄고, 관측데이터가 없으면 원은 움직임에 따라 커짐

#### - [State Estimation](http://jinyongjeong.github.io/2017/02/13/lec01_SLAM_bayes_filter/)_
- State estimation은 로봇에 주어지는 입력과, 로봇의 센서로부터 얻어지는 데이터로부터 현재의 로봇의 위치인 state와 주변환경에 대한 지도를 추정 방법

![image](https://user-images.githubusercontent.com/108650199/198465267-3db42c7b-86c6-43c5-839a-e96bea2be681.png)

- 위의 식은 기본적인 state estimation을 의미
  - x 는 로봇의 위치 및 지도(주변의 land mark들의 위치)를 의미하는 vector
  - z 는 로봇의 센서로부터 얻어지는 데이터로 observation
  - u 는 센서의 움직임을 제어하는 입력으로 control input
- state estimation은 이러한 control input과 observation의 데이터를 통해 현재의 위치와 지도를 추정

#### - bayes theorem
- 베이즈 정리는 확률론과 통계학에서 두 확률변수의 사전확률(prior)과 사후확률(posterior) 사이의 관계를 나타내는 정리

![image](https://user-images.githubusercontent.com/108650199/198465762-c34ddcd0-1280-4466-b1d0-362899a688d5.png)

  - P(A) 는 A의 prior로, 사건 B에 대한 어떠한 정보를 알지 못하는 것을 의미
  - P(A∣B) 는 B의 값이 주어진 경우 A의 posterior
  - P(B∣A) 는 A가 주어졌을 때 B의 조건부 확률

#### - Recursive bayes filter
- 위에서 설명한 state estimation은 bayes filter의 과정으로 설명할 수 있으며, 각 step의 state를 반복적으로 계산함으로써 계산할 수 있기 때문에 recursive bayes filter로 부름

![image](https://user-images.githubusercontent.com/108650199/198471052-692dfcbd-ba70-43bc-9ebd-23f3a05f5989.png)

- 위의 식은 recursive bayes filter를 유도하는 과정을 모두 표현하고 있기 때문에 다소 복잡해 보이지만
- 우선 전체적인 식을 이해하기 위해서 맨 처음과 맨 마지막 식만을 보면 다음과 같음

![image](https://user-images.githubusercontent.com/108650199/198466549-b2f5ed09-daf1-446d-af1e-7ec5949ad255.png)

- bel(Xt) 는 처음부터 현재까지의 observation(z)와 control input(u)을 알고 있을 때 현재 state(Xt)의 확률을 의미
- 위의 식에서 bel(Xt)의 식은 bel(Xt-1)의 integral로 표현되어 있기 때문에 만약 p(Zt|Xt)와 p(Xt|Xt-1,Ut)에 대한 정보를 알고 있다면 반복적인 계산을 통해 현재 state의 확률을 계산할 수 있음을 알 수 있음
  - 여기서, p(Zt|Xt)는 현재의 state에서 센서 데이터의 확률인 observation model
  - p(Xt|Xt-1,Ut)는  현재의 control input에 대해 이전 state에서 현재 state로의 update를 나타내는 motion model
- Recursive bayes filter는 Kalman filter의 기본

## 1.2 Kalman Filter and Extended Kalman Filter
#### - KF와 EKF의 공통점 및 차이점
- 1. 로봇의 state를 추정하기 위해 가장 흔히 사용되는 방법이며, Bayes filter를 따름
  - control input에 의한 prediction 단계와, 센서의 observation를 이용한 correction의 두 단계로 나뉨
- 2. 공통적으로 Gaussian 분포를 가정
  - KF는 선형 Gaussian 모델의 경우이며, EKF는 비선형 Gaussian 모델

#### - EKF 한계
- 1. Filtere base 방법은 어느 정도 Marcov의 특성을 가정
  - 즉, 시간 k에서의 상태는 k-1순간에만 관련되고, k-1이전에서 상태 및 관찰과는 독립적
  - 반면에 비선형 최적화 방법은 모든 데이터를 사용함
- 2. EKF는 테일러 급수로 선형화 한 후 선형화 된 결과를 기반으로 사후 확률 계산
  - 선형화 근사가 사후 확률에서도 영향이 있음
  - 즉, 만약 강한 비선형성을 가지면 선형 근사는 매우 작은 범위에서만 유효
- 3. EKF는 Pose의 Gaussian distribution을 따르므로 평균과 분산을 저장하고 유지하고 업데이트 해야 함
  - IF, 랜드마크도 상태로 넣으면 저장량 ↑
  - Pose가 제곱이 되므로(공분산 행렬 때문) Large scale에는 부적합
