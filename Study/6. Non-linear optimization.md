> Reference : [함수 최적화 기법 정리](https://darkpgmr.tistory.com/149)

Non-linear optimization
===
## 1. 일변수 함수 최적화(Optimization)
- 목적함수(Objective Function)를 최대한, 혹은 최소화하는 파라미터 조합을 찾는 과정
### 1.1 목적함수에 따른 최적화 분류
- 만약 목적함수가 f(x) = 2x + 1 등과 같이 하나의 파라미터(변수)로 되어 있다면 일변수 함수에 대한 최적화 문제가 됨
- f(x,y) = xy - x + 5 등과 같이 여러 개의 파라미터(변수)로 되어 있다면 다변수 함수에 대한 최적화 문제가 됨
- 선형 최적화(linear optimization) 문제 : 목적함수가 f(x1,x2,...,xm) = b + a1x1 + a2x2 + ... + amxm 과 같이 모든 파라미터(변수)에 대해 일차 이하의 다항식으로 구성
- 비선형 선형 최적화(non-linear optimization) 문제 : f(x,y) = ysinx + x, f(x,y) = x2 + y, f(x,y) = xy - 1 등과 같음
- 목적함수 외에 파라미터가 만족해야 할 별도의 제약조건이 있는 경우를 constrained optimization 문제
- 별도의 제약조건이 없는 경우를 unconstrained optimization 문제
- 최적화(optimization) 문제는 크게 최대화(maximization) 문제와 최소화(minimization) 문제로 나눌 수 있음
  - 최대화 : 목적함수가 이윤, 점수(score) 등인 경우
  - 최소화 : 비용(cost), 손실(loss), 에러(error) 등인 경우
  - 그런데, f를 최대화시키는 것은 -f를 최소화시키는 것과 동일하므로 방법론 상으로는 최대화 문제와 최소화 문제를 모두 동일하게 볼 수 있음

### 1.2 최적화 원리
- 현재 위치에서 함수값이 감소(최대화 문제라면 증가)하는 방향으로 조금씩 조금씩 파라미터 값을 이동해 나가는 것
- 계속 minimum이 될 때까지 내려가다가 더이상 내려갈 수 없는 곳(local minimum)이 될 때까지 반복

![image](https://user-images.githubusercontent.com/108650199/196320129-3fd4f562-4d37-44d1-8b44-0a20f2db93dc.png)

- 이 때, 가장 중요한 이슈는 어느 방향으로 내려갈 것인지와 한번에 얼마큼씩 이동할 것인지를 결정하는 것
  - 이러한 방법들이 가우스뉴턴, gradient descent, Levenberg-Marquardt방법 등이 있음
- 이동할 방향과 이동할 양을 결정할 때 사용되는 가장 기본적인 수학적 원리는 일차미분(기울기)과 이차미분(곡률)의 개념 

#### 1.2.1 일차미분 최적화
- 👉️ 일차미분을 이용한 최적화 기법을 Gradient Descent 방법이라 부름

> 일차미분을 이용한 최적화 원리

![image](https://user-images.githubusercontent.com/108650199/196343045-86ae4c41-f08a-4156-bda6-5b51dbe67c70.png)

- 일차미분(f')을 이용한 함수 최적화 기법의 가장 단순한 형태는 다음 수식에 따라 임의의 시작점 x0부터 시작하여 수렴할 때까지 x를 변화시키는 것

![image](https://user-images.githubusercontent.com/108650199/196343182-b7df09d8-d13b-4b5e-a328-bfa952f64b74.png)

- 여기서 λ는 한번에 얼마나 이동할지를 조절하는 step size 파라미터로서 일단은 고정된 상수(λ>0)로 가정
- 즉, 일차미분을 이용한 함수 최적화는 현재 지점에서 일차미분(기울기)이 양수(f'>0)이면 x를 감소시키고, 음수(f'<0)면 x를 증가시키는 방식으로 f가 극소(minima)가 되는 지점을 찾는 것
  - 여기서 step size를 잘 조정해야함
  - 만약 너무 작으면 속도가 느리고 오래 걸림
  - 만약 너무 크면 튀어버리는 현상 발생 

  ![image](https://user-images.githubusercontent.com/108650199/196343449-ca6adf81-ae92-41a4-94fc-d0c098308209.png)

#### 1.2.2 이차미분 최적화
- 앞서 설명한 일차미분을 이용한 최적화 기법의 문제점을 해결하기 위한 한 방법은 일차미분(f')과 함께 이차미분(f")을 이용하는 것
- 스텝 파라미터 λ를 요구하지 않는다는 특징을 가지며, 일차미분보다 속도가 빠름
  - f"을 이용하여 스텝의 크기를 스스로 결정
- 👉️ 뉴턴법(Newton's method), 가우스-뉴턴법(Gauss-Newton method), LM(Levenberg-Marquardt) 방법 등이 모두 이차 미분을 이용한 최적화 기법
##### - 문제점 
  - 변곡점(f"=0) 근처에서 매우 불안정한 이동 특성을 보인다는 점
  
  ![image](https://user-images.githubusercontent.com/108650199/196343207-e433f1c5-b0f2-45c5-8d15-6a07a48dd1db.png)
  
  - 이동할 방향을 결정할 때 극대, 극소를 구분하지 않는다는 점

  ![image](https://user-images.githubusercontent.com/108650199/196343482-a65da65e-e4ed-4ba8-ac3d-e24a7283164a.png)

#### 1.2.3 일차미분 vs 이차미분
- 정리해 보면 일차미분을 이용한 방법은 항상 옳은 방향을 향하지만 스텝(step)의 크기를 정하는데 어려움이 있음
- 이차미분을 이용한 방법은 보다 빠르게 해를 찾을 수 있지만 변곡점(f''=0) 근처에서 문제의 소지가 있으며 극대, 극소를 구분하지 못한다는 문제점
  - 사실 이차미분을 이용한 최적화는 테일러 급수(Taylor series)와 밀접한 관련이 있음

#### 1.2.4 Line Search : 일차미분 문제점 해결한 최적화 방법
- Line search 방법은 최적화 기법에서 스텝(step)의 크기를 결정하는 방법에 관한 것
- 앞서 일차미분을 이용한 최적화 기법은 항상 옳은 방향을 향하지만 스텝(step)의 크기를 정하는 것이 문제
  - 즉, 스텝의 크기가 너무 크면 발산의 위험이 있고 또한 극점 근처에서는 수렴 속도가 느려지는 문제점
    - 사실 이러한 문제의 원인은 스텝의 크기를 현재 지점에서의 국소적인 변화(f' 또는 f'')만을 보고 정하는데 있음
- Line search 방법은 이동하고자 하는 방향을 따라서 실제 함수값(f)의 변화를 미리 살펴본 후에 (함수값을 최소화하도록) 이동할 양을 결정하는 방식
- Line search 방법은 많지만, 직관적으로 이해할 수 있는 방법으로는 backtracking line search 과 golden section search 방법이 있음

![image](https://user-images.githubusercontent.com/108650199/196343512-8efde812-50db-46c5-a073-5a56d47e279a.png)

##### - backtracking line search
  - 일단 이동하고자 하는 방향을 따라서 최대한 멀리가서 해당 지점의 함수값이 현재의 함수값에 비해서 충분히 작아졌는지 검사
  - 만일 충분히 작지 않다면 점차적으로(보통 1/2씩) 거리를 줄여가면서 다시 함수값을 비교
  - 그래서 충분히 작아졌다고 판단이 되면 해당 지점으로 점프
  - 그리고 점프한 지점에서 다시 이동할 방향을 잡고 line search 알고리즘을 적용하는 방식 
    - Armijo–Goldstein 조건
      - 충분히 작아졌는지 여부는 현재 지점에서의 함수값을 f(xk), 이동하고자 하는 지점에서의 함수값을 f(xk + △x)라 할 때 f(xk + △x) - f(xk) ≤ △x*cf'(xk)를 만족하는지 여부로 결정  
##### - golden section search
  -  탐색구간의 내부를 황금비율인 1:1.618로 분할해 가면서 구간 내에서 함수값이 최소가 되는 지점을 탐색한 후 해당 지점으로 점프하는 방식

#### 1.2.5 Trust Region : 이차미분 문제점 해결한 최적화 방법

![image](https://user-images.githubusercontent.com/108650199/196343359-63228bfd-6ec7-43d7-9e52-32a3888e5b5c.png)

- 이차미분을 이용한 최적화 기법의 단점을 극복하기 위한 방법
- 사실 trust region 방법은 복잡한 함수의 변화를 좀더 단순한 함수로 근사(approximation)할 경우에 근사 정확도를 보장하기 위해서 사용되는 일반적인 방법이지만 여기서는 이차함수로 근사하는 경우로 한정하여 설명
- 앞서 설명했듯이 이차미분을 이용한 최적화 기법의 핵심 원리는 모든 구간에서 함수의 이차미분(f'') 값이 상수라고 가정하고 함수의 변화를 이차함수(quadratic function)로 근사한 후 근사 함수의 극점으로 이동하는데 있음
  - 그런데, 💥️ 이 가정의 가장 큰 문제점은 실제 함수는 이차함수가 아니라는데 있음 💥️ 
- Trust region 방법은 근사 함수에 대한 신뢰 영역(trust region)을 정의한 후 이동할 목적지에 대한 탐색 범위를 이 영역 내부로만 제한하는 방법
- 👉️ Levenberg-Marquardt 방법도 기본적으로는 trust region 방법에 속함

## 2. 다변수 함수 최적화
- 일변수 함수와 마찬가지로 다변수 함수의 경우에도 그대로 확장 적용될 수 있으며 그 특성 및 장단점도 모두 동일
- 앞서 최적화 기법들을 다변수 함수로 확장 적용하기 위해서는 미분을 어떻게 구하느냐가 관건
  - Gradient : 다변수 함수에 대한 일차 미분
  - Hessian	: 다변수 함수에 대한 이차 미분
  - Jacobian	: 다변수 벡터 함수에 대한 일차 미분
    
    > 왼쪽: gradient. 오른쪽: Hessian
    
    ![image](https://user-images.githubusercontent.com/108650199/196366678-ce8876e2-bdbe-46cc-8195-7ef35e28d5ea.png)
    
    - 그리고 그레디언트와 헤시안의 계산을 위해서는 편미분(partial differentiation)이 필요
    - 먼저, 다변수 함수란 f(x1, x2, x3) = x12 + x2x3 등과 같이 두개 이상의 변수에 의하여 함수값이 결정되는 함수
    - 편미분 : 어느 한 변수의 방향축에 대해서만 변화율을 구한 것으로 f의 x에 대한 편미분을 ∂f/∂x로 표기
    
    > Jacobian
    
    ![image](https://user-images.githubusercontent.com/108650199/196366697-a606f2d4-8869-4549-bb29-b73425378e8e.png)
  
    - 참고로, 자코비언(Jacobian)은 다변수 벡터 함수에 대한 일차 미분
    - 일차 미분을 이용한 최적화 기법을 다변수 함수로 확장하면 잘 알려진 gradient descent 방법이 됨
    - 단, x = (x1, x2, ..., xn)
    - 2차 미분을 이용한 최적화 기법을 다변수 함수로 확장하면 일반적인 Newton 방법이 됨

### 2.1 Non-linear least square(비선형 최소자승)
- 지금까지 설명한 최적화 기법들은 임의의 함수에 적용 가능한 일반적인 최적화 방법들
- 선형 모델의 경우에는 잔차의 제곱합이 기울기가 0이되는 지점에서 최소값을 가지지만 대부분은 비선형
- 하지만 목적함수(objective function)가 모델과 데이터 사이의 에러(error) 제곱합 형태로 주어지는 f(x) = Σei(x)2 형태의 최소자승(least squares) 문제에 대해서는 별도의 특화된 최적화 기법들을 존재
  - 이러한 방법에는 가우스-뉴턴법(Gauss-Newton method), Levenberg-Marquardt 방법 등
    - 하지만 이들은 최소자승 문제의 최적화에만 적용할 수 있고, 일반적인 최적화 문제에는 적용할 수 없는 방법임에 유의
    - 하지만 우리가 풀고자 하는 대부분의 최적화 문제들이 최소자승 문제에 해당
#### 2.2.1 Least Square의 이해

![image](https://user-images.githubusercontent.com/108650199/196354593-91c93caa-de91-4206-9ce4-f600e5369174.png)

- 임의의 모델의 파라미터를 구하는 한 방법으로서, 데이터와의 residual2의 합을 최소화하도록 모델의 파라미터를 구하는 방법
  - Least square은 overdetermined system이며 미지수의 갯수보다 식의 수가 더 많기 때문에, 모든 식을 만족하는 해가 존재하지 않는 시스템을 의미
- 상태를 알고 있을 때 예상되는 measurement를 예상할 수 있고, 실제 measurement와 예상되는 measurement와의 차이를 최소화 함으로써 최적화된 로봇의 state를 계산

![image](https://user-images.githubusercontent.com/108650199/196350944-d96f2730-a1be-413a-a305-dcdb35ebb83a.png)

![image](https://user-images.githubusercontent.com/108650199/196350912-f82a7f0b-2b78-4223-86aa-9f7901c76f47.png)

#### 2.2.2 Error function에서 minimum값 찾기

![image](https://user-images.githubusercontent.com/108650199/196351013-22e09ec0-966a-4357-bd7c-310da8b0cb88.png)

![image](https://user-images.githubusercontent.com/108650199/196351044-9e7b30ab-2e7c-4065-9c77-bf1041452b25.png)

  - 여기서 1. error term을 선형화할 때, 테일러 근사법을 사용하여 선형화
    - 테일러 근사법 : 어떤 미지의 함수 f(x)를 근사 다항함수로 표현하는 것
      - 테일러 급수가 필요한 이유는 쉽게 말하면 우리가 잘 모르거나 복잡한 함수를 다루기 쉽고 이해하기 쉬운 다항함수로 대체시키기 위함

#### 2.2.3 Least square의 한계
- 최소자승법은 데이터 중에 보통 outlier(정상적인 데이터 분포에서 동떨어진 데이터)라고 불리는 이상한 놈이 하나라도 끼어 있으면 적용하기 힘든 방법
  - 그 이유는 최소자승법은 전체 데이터의 residual2 합을 최소화하기 때문에 outlier의 residual도 같이 줄이려고 하다보면 전혀 엉뚱한(잘못된) 근사 결과를 낼 수 있기 때문
  - 따라서, outlier가 존재하는 경우에는 RANSAC, LMedS, M-estimator 등과 같은 robust한 파라미터 추정 방법을 사용
  - Robust한 파라미터 추정 방법들 중 가장 널리 쓰이는 일반적인 방법은 RANSAC이지만 outlier의 비율이 많지 않은 경우에는 M-estimator를 사용하는 것도 좋음
    - RANSAC이나 LMedS는 랜덤성이 있기 때문에 극단적인 경우 해를 못 찾을 수도 있기 때문
    - RANSAC : 최소자승법(least square method)은 데이터들과의 ∑residual2을 최소화하도록 모델을 찾지만, RANSAC은 컨센서스가 최대인, 즉 가장 많은 수의 데이터들로부터 지지를 받는 모델을 선택하는 방법으로 prior 정보가 없을 때도 신빙성 있는 모델 찾을 수 있음
    - but, RANSAC은 random성으로 인해 매번 결과가 달라짐
    - M-estimator : 모델 추정에 대한 좋은 initial guess가 있을 때 사용하면 좋음

    ![image](https://user-images.githubusercontent.com/108650199/196353983-1858caff-974b-4752-aa20-7c84641992ec.png)
    
    - LMedS : residual들의 median (residual들을 순서대로 정렬했을 때 순서상 가운데에 있는 값)이 최소화되는 모델을 찾으며, outlier 비율이 50% 이하일 경우에만 적용

### 2.2 Gradient Descent
- f'(x)가 0이 되는 점을 찾는 방법
- 어떤 함수의 극대점을 찾기 위해 현재 위치에서의 gradient 방향으로 이동해 가는 방법을 gradient ascent 방법, 극소점을 찾기 위해 gradient 반대 방향으로 이동해 가는 방법을 gradient descent 방법
- 어떤 다변수 함수 f(x1,x2,...,xn)가 있을 때, f의 gradient(그레디언트)는 ![image](https://user-images.githubusercontent.com/108650199/196357794-d8b5f518-345b-4189-b711-eabfe0e489e5.png) 와 같이 정의
- 즉, gradient(그레디언트)는 위 식과 같이 각 변수로의 일차 편미분 값으로 구성되는 벡터
  - 이 벡터는 f의 값이 가장 가파르게 증가하는 방향을 나타냄
  - 또한 벡터의 크기는 그 증가의 가파른 정도(기울기)를 나타냄

![image](https://user-images.githubusercontent.com/108650199/196361869-75da47e1-ffcf-4b06-8504-59a0095ff814.png)

- 즉, 어떤 초기값 x0 = (x10,...,xn0)부터 시작하여 위 식에 따라 gradient 반대 방향으로 x를 조금씩 이동시키면 f(x)가 극소가 되는 x를 찾을 수 있음
  - 여기서 λ는 알고리즘의 수렴속도를 조절하는 파라미터로서 step size 또는 learning rate라고 함

![image](https://user-images.githubusercontent.com/108650199/196361773-7f2b286b-f75d-4369-8d8f-326b18ffe59f.png)

### 2.3 Newton
- 방정식 f(x) = 0의 해를 근사적으로 찾을 때 사용되는 방법
- 현재 x값에서 접선을 그리고 접선이 x축과 만나는 지점으로 x를 이동시켜 가면서 점진적으로 해를 찾아가는 방법

![image](https://user-images.githubusercontent.com/108650199/196363719-aa8e524f-ba68-4514-9f85-fce5953919b2.png)

- 뉴턴법(Newton's method)을 수식화하면 아무 값이나 초기값 x1에서 시작해서 다음 수식에 따라 수렴할 때까지 계속 x를 이동
- 임의의 점에서 같은 기울기를 가지는 이차함수로 근사시키는 것과 동일
##### - 장점 
- Gradient Descent와 다르게 하이퍼 파라미터가 없으며 local minimum 근처에서도 빠르게 수렴
##### - 단점
- 두번 미분 가능
- 변곡점 또는 이와 유사한 값이 존재해서는 안됨
- 극대와 극소의 구분이 어려움

### 2.4 Gauss-Newton
- Non-linear least square 형태의 목적함수에 최적화
- 연립방정식의 근사해를 구할 때는 가우스-뉴턴(Gauss-Newton) 방법을 사용
  - 즉, 가우스-뉴턴 방법은 뉴턴법을 연립방정식으로 확장한 것으로 볼 수 있음
##### - [Gauss-Newton method](http://www.cv-learn.com/20210314-nonlinear-optimisation/)
- 입력 데이터가 Gaussian 분포를 따르고 있다는 전제 하에, Least-squares 최적화 과정은 Maximum likelihood estimation으로 변환
  - 즉, 통계적으로 optimal한 해를 구할 수 있음
- 한번에 Optimal한 해는 구하기 어려우며, 올바른 방향으로 iterative하게 최적화
- Non-linear한 manifold 위에서 최적화 방향을 잡기 위해 1차 미분을 수행
  - 1차 미분은 Taylor expansion으로 근사
- 1차 미분 후 정리하면 2차 방정식 형태로 정리
- 여기서 ![image](https://user-images.githubusercontent.com/108650199/196371445-fe04cee0-1bb8-4bf2-9fc6-6c0488386594.png) 는 Hessian matrix로 근사
  - Hi는 선형화 후의 information matrix
- 2차 방정식은 미분한 결과가 0일 때, 최소값 또는 최대값을 얻을 수 있음
- global error function을 최소로 만드는 state인 △x를 계산하여, 결과를 이용하여 state를 update
##### - [Least square과 Gauss-Newton의 관계(파라미터)](https://darkpgmr.tistory.com/m/58)
- 관측값을 (xi, yi), 모델 파라미터를 β = ( β1,  β2, ...,  βm) , 모델을 y = f(x, β)라 할때, 알다시피 최소자승법은 residual인 ri = yi - f(xi, β)들의 제곱합을 최소로 하는 모델 파라미터 β를 찾는 방법

![image](https://user-images.githubusercontent.com/108650199/196374537-77f2456f-cd6b-4cc8-99c0-fb3b5178ebdb.png)

- 이는, 원래는 다음과 같은 연립 방정식을 푸는 문제이기 때문에 앞서 설명한 '가우스-뉴턴법을 이용한 연립방정식의 근사해 구하기'를 이용해서 β를 구할 수 있음

![image](https://user-images.githubusercontent.com/108650199/196374580-6e95a266-68fa-4051-870b-ad0a50642ee3.png)

### 2.5 Levenberg–Marquardt
- 가우스-뉴턴법(Gauss–Newton method)과 gradient descent 방법이 결합된 형태로서 해로부터 멀리 떨어져 있을 때는 gradient descent 방식으로 동작하고 해 근처에서는 Gauss-Newton 방식으로 해를 찾음
- 뉴턴법보다 안정적으로 해를 찾을 수 있으며(초기값이 해로부터 멀리 떨어진 경우에도 해를 찾을 확률이 높음) 비교적 빠르게 해에 수렴하기 때문에 비선형 최소자승문제에 있어서는 대부분 Levenberg–Marquardt 방법이 사용

![image](https://user-images.githubusercontent.com/108650199/196376735-665d1c75-b6fa-433e-9377-e9dcb0968420.png)



### [정리](https://darkpgmr.tistory.com/m/142)
> [Reference](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=tlaja&logNo=220735045887)

![image](https://user-images.githubusercontent.com/108650199/196378826-ebbbd098-f954-439e-a54b-08c84fcfd248.png)

#### - Gradient Descent

![image](https://user-images.githubusercontent.com/108650199/196378873-5fa08f68-82d2-439a-b482-e8c2ffc8ed30.png)

- 그레디언트의 반대방향으로 이동하되 그레디언트의 크기에 비례한 step size 만큼씩 이동하면서 해(에러함수를 최소화시키는 극소점)를 찾아가는 방법
  
#### - Gauss-Newton

![image](https://user-images.githubusercontent.com/108650199/196378919-79527edf-a2c7-4dea-8069-1bd5fc423ced.png)

- 가우스-뉴턴법은 함수의 그레디언트와 곡률(curvature)을 같이 고려하면서 해를 찾아가는 방식
  - 식에서 JrTJr는 이차미분인 Hessian의 의미를 가지며(Hessian에 대한 근사행렬) 함수의 곡률을 나타냄
- 즉, 이동할 step size를 (그레디언트의 크기)/(곡률의 크기)로 결정하는 방식
  - 기울기(그레디언트)가 크더라도 곡률이 크면(기울기의 변화가 급격하면) 조금만 이동하고, 곡률이 작다면(기울기의 변화가 거의 없으면) 좀더 크게 이동함으로써 극소점을 찾아가는 방식
  - 따라서, 가우스-뉴턴법은 gradient descent 방법보다 훨씬 정확하고 빠르게 해를 찾을 수 있다는 장점
- 그런데, 가우스-뉴턴법을 살펴보면 계산 과정에 (JrTJr)의 역행렬 계산을 필요
- 따라서 (JrTJr)가 singular 행렬(역행렬이 존재하지 않는 행렬)에 근접한 경우에는 계산된 역행렬이 수치적으로 불안정하여 해가 발산할 수 있는 문제점

#### - Levenberg

![image](https://user-images.githubusercontent.com/108650199/196379479-c424e8b7-e44d-46d7-aba7-cd06528cc647.png)

- Levenberg 방법은 가우스-뉴턴법을 개선하여 JrTJr에 항등행렬(identity matrix)의 상수배 μI를 더함으로써 발산의 위험성을 낮추고 보다 안정적으로 해를 찾을 수 있도록 한 방법
- 상수 μ(μ>0)를 damping factor라 부르는데 μ값이 작으면 Levenberg 방법은 가우스-뉴턴법과 유사해지고 μ값이 크면 gradient descent 방법과 유사
- 수식에서 μ→∞ 면 (JrTJr+μI)-1→1/μI이므로 μ가 커지면 Levenberg 방법은 스텝의 크기가 1/μ인 gradient descent 방법과 유사해짐을 알 수  있음
- 그런데, Levenberg 방법에서 damping factor μ는 고정된 값이 아니라 매 iteration마다 바뀌는 값으로서 현재 안정적으로 해에 수렴하고 있을 경우에는 작은 값을 주고 해를 잘 찾지 못하고 있을 경우에는 큰 값을 주는 방법을 사용
  - 좀더 구체적으로 설명하면, 현재 단계에서 계산된 에러 E(pk)가 이전의 에러 E(pk-1)에 비해 잘 감소하고 있으면 μk에 작은 값을 사용하여 가우스-뉴턴 방식으로 해를 찾고 오히려 에러가 증가하거나 에러 감소가 충분치 않은 경우에는 μk를 증가시켜서 gradient descent 방식으로 해를 찾는 방식

#### - Levenberg-Marquardt 

![image](https://user-images.githubusercontent.com/108650199/196379908-984ad2e7-ec8f-4e9f-a01a-6a4ee0ab3113.png)

- 기존의 Levenberg의 방법을 1963년에 Marquardt가 좀더 개선시킨 방법
- 원래의 Levenberg 방법은 μ가 큰 경우에 step size가 1/μ가 되므로, 하지만 이 경우 수렴 속도가 느린 문제점
  - Marquardt는 이러한 문제를 보완하기 위해 항등행렬 I 대신에 diag(JrTJr) 더해주는 방식을 제안
    - diag(A)는 A의 대각원소는 유지하고 나머지 원소들의 값을 0으로 만든 대각행렬을 나타냄
  - JrTJr은 원래 헤시안(Hessian)에 대한 근사행렬의 의미를 갖기 때문에 JrTJr의 대각 원소들은 각 파라미터 성분(pi)에 대한 곡률(curvature)를 나타냄
  - 즉, Levenberg-Marquardt 방법은 가우스-뉴턴법의 singular 문제를 피하면서도 μ가 큰 경우에도 곡률(curvature)을 반영하여 효과적으로 해를 찾을 수 있도록 한 방법
- 여기서 JrTJr는 아래식과 같이 Hessian 행렬의 근사값이 됨

![image](https://user-images.githubusercontent.com/108650199/196381063-9a080ab7-46a3-4d86-9d04-e0be58b17125.png)

- diag(JrTJr) 는 Hessian 행렬의 대각행렬로서 Hessian 행렬의 고유값 즉, 곡률을 의미
